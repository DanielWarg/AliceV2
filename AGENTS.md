# Alice v2 AGENTS.md
*Instructions and context for AI coding agents working on Alice AI Assistant*

---

## ğŸš€ **CURRENT PROJECT STATUS (Updated 2025-08-31)**

### **âœ… COMPLETED - LLM Integration v1 + Complete Observability System**

Alice v2 har transformerats frÃ¥n prototyp till **robust, production-ready platform** med komplett LLM-integration, sÃ¤kerhets-, Ã¶vervaknings-, testramverk och **autonom E2E-validering**:

**ğŸ¤– LLM Integration v1:**
- âœ… **Intelligent routing**: Micro (Phi-mini), Planner (Qwen-MoE), Deep (Llama-3.1) med pattern matching
- âœ… **LLM drivers**: Ollama integration med proper timeouts och error handling
- âœ… **Planner execution**: JSON schema validation och tool execution med fallback matrix
- âœ… **Guardian-aware**: Deep blocked i brownout, planner degraded under resurstryck
- âœ… **Fallback system**: LLM + tool fallback med max 1 kedja per turn
- âœ… **SLO compliance**: Fast â‰¤250ms, planner â‰¤1500ms, deep â‰¤3000ms

Alice v2 har transformerats frÃ¥n prototyp till **robust, production-ready platform** med komplett sÃ¤kerhets-, Ã¶vervaknings-, testramverk och **autonom E2E-validering**:

**ğŸ›¡ï¸ Guardian Safety System:**
- âœ… Real-time health monitoring med NORMAL/BROWNOUT/EMERGENCY states
- âœ… 5-punkts sliding window RAM/CPU monitoring (80%/92% trÃ¶sklar)
- âœ… 60-sekunds recovery hysteresis fÃ¶r stabil tillstÃ¥ndshantering
- âœ… Admission control som skyddar systemet under resurstryck

**ğŸ“Š Complete Observability System:**
- âœ… **RAM-peak per turn**: Process och system memory tracking i varje turn event
- âœ… **Energy per turn (Wh)**: Energikonsumtion med konfigurerbar baseline
- âœ… **Tool error classification**: Timeout/5xx/429/schema/other kategorisering med Prometheus metrics
- âœ… **Structured turn events**: Komplett JSONL logging med alla metrics och metadata
- âœ… **Real-time dashboard**: Streamlit HUD visar RAM, energi, latens, tool-fel och Guardian status

**ğŸ§ª Autonomous E2E Testing:**
- âœ… **Self-contained validation**: `scripts/auto_verify.sh` kÃ¶r komplett systemvalidering
- âœ… **20 realistiska scenarier**: Svenska samtal som tÃ¤cker micro/planner/deep routes
- âœ… **SLO validation**: Automatisk P95 threshold checking med Node.js integration
- âœ… **Failure detection**: Exit kode 1 vid SLO-brott eller <80% pass rate
- âœ… **Artifact preservation**: Alla testresultat sparas till `data/tests/` och `test-results/`

**ğŸ“ˆ Production Observability:**
- âœ… Streamlit HUD med real-time Guardian timeline (rÃ¶d/gul/grÃ¶n)
- âœ… Route latency trends, error budget burn rates, SLO compliance tracking
- âœ… JSONL observability logging till `/data/telemetry` med PII masking
- âœ… Auto-refresh monitoring lÃ¤mpligt fÃ¶r DevOps-team

**âš¡ Complete Brownout Load Testing:**
- âœ… 5 stress test modules: Deep-LLM, Memory balloon, CPU spin, Tool storm, Vision RTSP
- âœ… SLO validation: â‰¤150ms brownout trigger, â‰¤60s recovery measurement
- âœ… Real brownout trigger/recovery testing med Guardian state monitoring
- âœ… Structured JSONL telemetry fÃ¶r trendanalys

**ğŸ³ Production Deployment:**
- âœ… Docker Compose orchestration med health checks och dependencies
- âœ… Environment-driven konfiguration med production-safe defaults
- âœ… Komplett dokumentation och setup scripts

---

## ğŸ“‹ **WHAT WE BUILT - Technical Deep Dive**

### **Core Services Architecture**

```
alice-v2/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ orchestrator/    # âœ… LLM routing & API gateway med LLM integration v1
â”‚   â”‚   â”œâ”€â”€ src/llm/ollama_client.py   # Ollama client med timeouts
â”‚   â”‚   â”œâ”€â”€ src/llm/micro_phi.py       # Phi-mini driver fÃ¶r snabba svar
â”‚   â”‚   â”œâ”€â”€ src/llm/planner_qwen.py    # Qwen-MoE driver med JSON output
â”‚   â”‚   â”œâ”€â”€ src/llm/deep_llama.py      # Llama-3.1 driver med Guardian integration
â”‚   â”‚   â”œâ”€â”€ src/router/policy.py       # Intelligent routing med pattern matching
â”‚   â”‚   â”œâ”€â”€ src/planner/schema.py      # JSON schema fÃ¶r tool execution
â”‚   â”‚   â”œâ”€â”€ src/planner/execute.py     # Plan execution med fallback matrix
â”‚   â”‚   â”œâ”€â”€ src/utils/ram_peak.py      # RAM-peak per turn tracking
â”‚   â”‚   â”œâ”€â”€ src/utils/energy.py        # Energy per turn measurement
â”‚   â”‚   â”œâ”€â”€ src/utils/tool_errors.py   # Tool error classification
â”‚   â”‚   â”œâ”€â”€ src/metrics.py             # Real P50/P95 tracking
â”‚   â”‚   â”œâ”€â”€ src/mw_metrics.py          # ASGI latency middleware  
â”‚   â”‚   â”œâ”€â”€ src/guardian_client.py     # Guardian integration
â”‚   â”‚   â”œâ”€â”€ src/status_router.py        # Status API endpoints
â”‚   â”‚   â””â”€â”€ src/routers/orchestrator.py # LLM integration + turn logging
â”‚   â”‚
â”‚   â”œâ”€â”€ guardian/        # âœ… 5-point sliding window safety
â”‚   â”‚   â””â”€â”€ main.py      # NORMALâ†’BROWNOUTâ†’EMERGENCY state machine
â”‚   â”‚
â”‚   â”œâ”€â”€ eval/            # âœ… Autonomous E2E testing harness
â”‚   â”‚   â”œâ”€â”€ eval.py       # 20 scenarios, SLO validation
â”‚   â”‚   â”œâ”€â”€ scenarios.json # Test cases covering all routes
â”‚   â”‚   â””â”€â”€ requirements.txt # Dependencies
â”‚   â”‚
â”‚   â””â”€â”€ loadgen/         # âœ… Complete brownout testing suite
â”‚       â”œâ”€â”€ main.py      # Orchestrates stress + measures SLO
â”‚       â”œâ”€â”€ watchers.py  # MÃ¤ter brownout trigger/recovery latency
â”‚       â””â”€â”€ burners/     # 5 stress test modules
â”‚
â”œâ”€â”€ monitoring/          # âœ… Streamlit production HUD
â”‚   â”œâ”€â”€ alice_hud.py     # Real-time Guardian + metrics visualization
â”‚   â””â”€â”€ mini_hud.py      # Lightweight dashboard fÃ¶r eval results
â”‚
â”œâ”€â”€ scripts/             # âœ… Autonomous E2E test automation + port management
â”‚   â”œâ”€â”€ auto_verify.sh   # Complete system validation script
â”‚   â”œâ”€â”€ ports-kill.sh    # Port cleanup script
â”‚   â””â”€â”€ start-llm-test.sh # LLM integration test script
â”‚
â”œâ”€â”€ data/telemetry/      # âœ… Structured JSONL logging
â”œâ”€â”€ data/tests/          # âœ… E2E test artifacts
â””â”€â”€ test-results/        # âœ… Nightly validation trends
```

### **Key Technical Implementations**

**LLM Integration v1 (services/orchestrator/src/routers/orchestrator.py):**
```python
# Route to appropriate model using LLM Integration v1
route = route_request(chat_request)
logger.info("Route selected", route=route)

# Generate response based on route
if route == "micro":
    micro_driver = get_micro_driver()
    llm_response = micro_driver.generate(chat_request.message)
elif route == "planner":
    planner_driver = get_planner_driver()
    llm_response = planner_driver.generate(chat_request.message)
    # Execute plan if JSON was parsed successfully
    if llm_response.get("json_parsed") and llm_response.get("plan"):
        planner_executor = get_planner_executor()
        plan = planner_executor.validate_plan(llm_response["plan"])
        if plan:
            planner_execution = planner_executor.execute_plan(plan)
elif route == "deep":
    deep_driver = get_deep_driver()
    llm_response = deep_driver.generate(chat_request.message)
```

**Turn Event Logging (services/orchestrator/src/routers/orchestrator.py):**
```python
def log_turn_event(trace_id: str, session_id: str, route: str, 
                   e2e_first_ms: float, e2e_full_ms: float,
                   ram_peak_mb: Dict[str, float], energy_wh: float,
                   tool_calls: List[Dict], guardian_state: str):
    """Logga komplett turn event med alla metrics"""
    event = {
        "v": "1", "ts": datetime.utcnow().isoformat() + "Z",
        "trace_id": trace_id, "session_id": session_id, "route": route,
        "e2e_first_ms": e2e_first_ms, "e2e_full_ms": e2e_full_ms,
        "ram_peak_mb": ram_peak_mb, "energy_wh": energy_wh,
        "tool_calls": tool_calls, "guardian_state": guardian_state
    }
    # Skriv till JSONL fil
```

**Autonomous E2E Testing (scripts/auto_verify.sh):**
```bash
#!/usr/bin/env bash
# Startar tjÃ¤nster, vÃ¤ntar pÃ¥ hÃ¤lsa, kÃ¶r eval, validerar SLO
docker compose up -d orchestrator guardian
# VÃ¤ntar pÃ¥ hÃ¤lsa...
./services/eval/eval.py  # KÃ¶r 20 scenarier
# Node.js SLO validation...
# Exit 1 vid SLO-brott eller <80% pass rate
```

**Eval Harness (services/eval/eval.py):**
```python
def run_chat(text, session="eval"):
    payload = {"v":"1","session_id":f"{session}-{uuid.uuid4().hex[:6]}",
               "lang":"sv","text":text}
    t0 = time.perf_counter()
    with httpx.Client(timeout=10) as c:
        r = c.post(f"{API}/api/chat", json=payload)
    dt = (time.perf_counter()-t0)*1000
    return r, dt
```

---

## ğŸ¯ **NEXT PRIORITIES - Where to Go From Here**

### **HIGH PRIORITY (Ready for Next AI Agent)**

1. **ğŸ¤ Voice Pipeline Implementation**
   - **Current**: Arkitektur klar, services stubbed
   - **Next**: ASRâ†’NLUâ†’TTS pipeline med WebSocket connections  
   - **Location**: `services/voice/` (needs implementation)
   - **Swedish Focus**: Whisper ASR, svenska sprÃ¥kmodeller
   - **Testing**: UtÃ¶ka `services/eval/scenarios.json` med voice scenarios

2. **ğŸŒ Web Frontend Integration**
   - **Current**: Next.js app structure i `apps/web/`
   - **Next**: Koppla frontend till Orchestrator API
   - **Features**: Chat UI, Guardian status display, voice controls
   - **Validation**: Integrera frontend i `auto_verify.sh` E2E test

2. **ğŸ¤ Voice Pipeline Implementation**
   - **Current**: Arkitektur klar, services stubbed
   - **Next**: ASRâ†’NLUâ†’TTS pipeline med WebSocket connections  
   - **Location**: `services/voice/` (needs implementation)
   - **Swedish Focus**: Whisper ASR, svenska sprÃ¥kmodeller
   - **Testing**: UtÃ¶ka `services/eval/scenarios.json` med voice scenarios

3. **ğŸŒ Web Frontend Integration**
   - **Current**: Next.js app structure i `apps/web/`
   - **Next**: Koppla frontend till Orchestrator API
   - **Features**: Chat UI, Guardian status display, voice controls
   - **Validation**: Integrera frontend i `auto_verify.sh` E2E test

### **MEDIUM PRIORITY**

4. **ğŸ“¦ Package System Completion**
   - **Current**: TypeScript packages i `packages/`
   - **Next**: Komplettera API client, types, UI components
   - **Purpose**: Shared kod mellan services och frontend

5. **ğŸ”§ Advanced Monitoring**  
   - **Current**: Streamlit HUD med comprehensive metrics
   - **Next**: Prometheus/Grafana integration, alerting
   - **Location**: UtÃ¶ka `monitoring/` med metrics exporters

### **LOW PRIORITY (Future Iterations)**

6. **ğŸ¤– Advanced AI Features**
   - Multi-modal processing (text + voice + vision)
   - Context retention across sessions
   - Learning frÃ¥n user interactions

7. **âš¡ Performance Optimization**
   - LLM response caching
   - Load balancing fÃ¶r multiple instances
   - Database integration fÃ¶r persistent state

---

## ğŸ› ï¸ **DEVELOPMENT CONTEXT FOR NEXT AI**

### **How We Work - Proven Approach**

**âœ… Autonomous E2E Testing:**
```bash
# Komplett systemvalidering med en kommand
./scripts/auto_verify.sh
# Startar tjÃ¤nster, kÃ¶r eval, validerar SLO, sparar artifacts
```

**âœ… Real Integration Testing (No Mocks):**
```bash
# Vi testar mot riktiga services med realistiska fÃ¶rvÃ¤ntningar
pytest src/tests/test_real_integration.py -v
# Success rate: 80-95% (inte 100% perfectionism)
```

**âœ… Production-Tight Development:**
```bash  
# Starta hela stacken fÃ¶r development
docker compose up -d guardian orchestrator

# KÃ¶r autonom validering
./scripts/auto_verify.sh

# Ã–vervaka i realtid  
cd monitoring && streamlit run mini_hud.py
```

**âœ… Structured Development Workflow:**
1. **Plan**: AnvÃ¤nd TodoWrite fÃ¶r att tracka tasks
2. **Implement**: Real integration frÃ¥n bÃ¶rjan (inga mocks)
3. **Test**: KÃ¶r `./scripts/auto_verify.sh` fÃ¶r komplett validering
4. **Monitor**: AnvÃ¤nd HUD fÃ¶r att se impact i realtid
5. **Validate**: SLO compliance via autonomous testing

### **Architecture Principles to Follow**

- **Safety First**: Guardian ska alltid vara fÃ¶rsta prioritet
- **Real Data**: MÃ¤t verkliga metrics, inte mocks eller estimates
- **Production Ready**: Allt ska vara deployment-ready frÃ¥n dag 1
- **Observable**: Logga structured data fÃ¶r debugging och ML training
- **Autonomous Testing**: Alla features ska valideras via `auto_verify.sh`
- **Swedish Focus**: Alice Ã¤r optimerad fÃ¶r svenska anvÃ¤ndare

### **Code Conventions Established**

- **Python Services**: FastAPI + Pydantic, strukturerad logging med structlog
- **Testing**: pytest med realistic expectations (80-95% success rates)  
- **E2E Testing**: `scripts/auto_verify.sh` fÃ¶r komplett validering
- **Monitoring**: JSONL fÃ¶r structured logging, Streamlit fÃ¶r dashboards
- **Docker**: Health checks, proper dependencies, environment-driven config
- **Git**: Descriptive commits med ğŸ¤– Claude Code signature

### **Files You Should Read First**

1. **`README.md`** - Production deployment guide
2. **`ALICE_SYSTEM_BLUEPRINT.md`** - System architecture  
3. **`TESTING_STRATEGY.md`** - Our proven testing approach
4. **`scripts/auto_verify.sh`** - Autonomous E2E testing
5. **`services/eval/eval.py`** - Eval harness implementation
6. **`services/orchestrator/main.py`** - Current integration points
7. **`monitoring/mini_hud.py`** - Real-time system visibility

### **Key Environment Setup**

```bash
# Repository navigation
cd alice-v2

# Start production stack
docker compose up -d guardian orchestrator

# Development environment  
cd services/orchestrator
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Test everything works
curl http://localhost:8000/api/status/simple
curl http://localhost:8787/health

# Run autonomous validation
./scripts/auto_verify.sh

# Start monitoring
cd monitoring && streamlit run mini_hud.py
```

---

## ğŸ”® **STRATEGIC DIRECTION**

Alice v2 har gÃ¥tt frÃ¥n prototyp till **production-ready platform med komplett observability och autonom E2E-testing**. NÃ¤sta AI agent kan fokusera pÃ¥ **actual LLM integration** och **voice pipeline** medan hela safety/monitoring/test infrastrukturen redan Ã¤r robust.

**Key Success Factors:**
- Guardian sÃ¤kerhetsystem ger trygg LLM experimentation 
- Complete observability ger immediate feedback pÃ¥ fÃ¶rÃ¤ndringar
- Autonomous E2E testing validerar att nya features inte bryter SLO
- HUD dashboard ger visual confirmation att allt fungerar

**Philosophy**: Vi bygger inte bara en AI assistant - vi bygger en **robust, observable, sÃ¤ker plattform** som kan utvecklas iterativt utan att kompromissa pÃ¥ kvalitet eller sÃ¤kerhet, med autonom validering av alla fÃ¶rÃ¤ndringar.

---

**ğŸ¤– Status Updated by Claude Code - Alice v2 observability + eval-harness v1 complete! Ready for LLM integration! ğŸš€**

---

## âš¡ NEXT AI QUICKSTART (Dev-Proxy - No Mocks)

Snabbstart fÃ¶r nÃ¤sta AI-agent â€“ allt via dev-proxy pÃ¥ port 18000.

### 1) Starta stacken
```bash
scripts/dev_up.sh
# eller
docker compose up -d guardian orchestrator nlu dashboard dev-proxy
```

### 2) Sanity via proxy
```bash
curl -s http://localhost:18000/health | jq .
curl -s http://localhost:18000/api/status/routes | jq .
```

### 3) NLU sanity (svenska)
```bash
curl -s -X POST http://localhost:18000/api/nlu/parse \
  -H 'Content-Type: application/json' \
  -d '{"v":"1","lang":"sv","text":"Boka mÃ¶te med Anna imorgon kl 14","session_id":"nlu-sanity"}' | jq .
```

### 4) E2E verify (autonomt)
```bash
./scripts/auto_verify.sh || (echo "FAIL â€“ se data/tests/summary.json" && exit 1)
cat data/tests/summary.json | jq .
open http://localhost:18000/hud
```

### 5) NLU v1 â€“ DoD (nÃ¤sta steg)
- `/api/nlu/parse` P95 â‰¤ 80 ms (5 min fÃ¶nster)
- Intent-accuracy â‰¥ 92% (svensk svit)
- Slots: ISO fÃ¶r uttryck som â€œimorgon 14:00â€
- Orchestrator sÃ¤tter `X-Route-Hint` â†’ route syns i P95 per route
