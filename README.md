```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                               ‚ïë
‚ïë      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó    ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó                   ‚ïë
‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó                  ‚ïë
‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó      ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù                  ‚ïë
‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù      ‚ïö‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù                   ‚ïë
‚ïë     ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó     ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó                  ‚ïë
‚ïë     ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù      ‚ïö‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù                  ‚ïë
‚ïë                                                                               ‚ïë
‚ïë   Swedish NLU v2 Training System + OPUS NLU Phase 1 Production Complete       ‚ïë
‚ïë                                                                               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

![E2E](https://img.shields.io/badge/E2E-Auto--verify-green)
![SLO](https://img.shields.io/badge/SLO-Per--route%20P95-green)
![Privacy](https://img.shields.io/badge/Privacy-GDPR%20by%20design-blue)
![Training](https://img.shields.io/badge/Training-Anti--mode--collapse-purple)
![Watchdog](https://img.shields.io/badge/Watchdog-Comprehensive%20Monitoring-orange)

> **üö¶ Status (live-gates)**: OPUS NLU Phase 1 ‚úÖ (Math F1: 0.653, Macro F1: 0.434, P95: 70.3ms) | Phase 2 Training ‚úÖ (TrainingWatchdog operational)  
> **Current Focus**: Swedish NLU v2 with anti-mode-collapse training, WeightedRandomSampler, and comprehensive monitoring systems.

## üéØ Quick Demo (30 seconds)

```bash
git clone https://github.com/DanielWarg/AliceV2.git && cd alice-v2
make up
open http://localhost:3000   # Next.js Frontend
```

![Alice v2 HUD](hud.png)
*Real-time Swedish AI assistant with Guardian monitoring, training watchdog, and comprehensive observability*

## üéØ Project Overview

Alice v2 represents three completed phases of Swedish AI development:

**üéØ OPUS NLU Phase 1 (PRODUCTION COMPLETE - Sep 11, 2025):**
- ‚úÖ **Math F1: 0.653** (‚â•0.60 required) - Swedish number translation breakthrough
- ‚úÖ **Macro F1: 0.434** (‚â•0.25 required) 
- ‚úÖ **P95 Latency: 70.3ms** (<100ms required)
- ‚úÖ **Hallucination Rate: 0.0%** (<20% required)
- ‚úÖ **Safety Precision: 100%** (‚â•95% required)
- ‚úÖ **Golden Test Set**: 300 Swedish expressions with SHA256 freeze
- ‚úÖ **Production Tagged**: `nlu-hybrid-v1.0-phase1`

**üêï Swedish NLU v2 Training System (COMPLETE - Sep 12, 2025):**
- ‚úÖ **TrainingWatchdog** - Comprehensive monitoring for divergence, performance regression, overfitting, hallucination, and mode collapse
- ‚úÖ **Anti-Mode-Collapse Measures** - WeightedRandomSampler, class-balanced loss, frozen encoder policy (10/12 layers)
- ‚úÖ **Swedish Math FN Fixes** - Fixed 3 critical patterns: "50 procent av 200", "femton delat med tre", "h√§lften av tjugo"
- ‚úÖ **Balanced Dataset** - 280 samples (206 train / 37 val / 37 test) with ‚â•30 samples per intent
- ‚úÖ **Coverage Slope Monitoring** - Box-counting method with -1.8 baseline for mode collapse detection
- ‚úÖ **OPUS Gates Implementation** - Math F1 ‚â•0.60, Macro F1 ‚â•0.25, Hallucination <1%, Safety precision ‚â•95%

**üñ•Ô∏è Next.js Enterprise Frontend (COMPLETE - Sep 12, 2025):**
- ‚úÖ **Advanced React/Next.js Interface** - Real-time chat with Alice orchestrator integration
- ‚úÖ **Enterprise HUD** - Live system metrics, health monitoring, and visual feedback  
- ‚úÖ **Swedish Language Support** - Native Swedish UI with cultural context
- ‚úÖ **Mobile-Responsive Design** - Dark theme with PWA capabilities

**üéôÔ∏è Voice Pipeline System (AVAILABLE - Port 8002):**
- üîß **Swedish TTS/STT Pipeline** - Whisper + Piper voice models
- üîß **Audio Processing** - VAD threshold tuning for Swedish speech
- üîß **Voice Integration** - Connected to Alice orchestrator for full conversations

**üèóÔ∏è Supporting Infrastructure:**
- **üõ°Ô∏è Guardian Safety System** - Brownout/EMERGENCY protection with kill-sequence
- **üíæ Smart Cache L1/L2/L3** - Semantic matching with deterministic fingerprinting  
- **üß† Memory Service** - FAISS vector store + Redis for RAG pipeline and user context
- **üß™ E2E Testing System** - Multi-vector stress tests (CPU/Memory/Tool/Vision) with brownout testing
- **üîí Security Engine** - Policy enforcement, PII masking, rate limits, tool gate protection
- **ü§ñ RL/ML System** - LinUCB Router + Thompson Sampling for multi-armed bandit optimization and DPO training
- **‚öñÔ∏è œÜ-Optimization** - Fibonacci ratios for precision/latency/energy/safety reward calculation
- **üåí Shadow Mode** - A/B testing with 5% production traffic canary deployment and safe model evaluation
- **üí∞ Cost Management** - OpenAI token tracking with budget enforcement and auto-fallback
- **üìä Real-time Monitoring** - Streamlit dashboard (port 8501) with comprehensive metrics
- **üê≥ Docker Orchestration** - Complete deployment with `make up`

## üìö Index (Solo Edition)
- Solo Quickstart ‚Äì see below
- Demo Guide ‚Äì see below  
- Windows Setup Guide ‚Äì see below
- Training Documentation ‚Äì `training/` (TrainingWatchdog, anti-mode-collapse)
- Roadmap ‚Äì `ROADMAP.md`
- Architecture ‚Äì `ALICE_SYSTEM_BLUEPRINT.md`
- Rules/specs ‚Äì `.cursor/rules/` (PRD, ADR, workflow, types, structured-outputs, toolselector, n8n)

## üèóÔ∏è Architecture

### Complete System Architecture
```
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ                    FRONTEND LAYER                       ‚îÇ
                     ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                     ‚îÇ  ‚îÇ    Web UI   ‚îÇ    ‚îÇ    Voice    ‚îÇ    ‚îÇ   Mobile    ‚îÇ  ‚îÇ
                     ‚îÇ  ‚îÇ (React/WS)  ‚îÇ    ‚îÇ   (8002)    ‚îÇ    ‚îÇ    App      ‚îÇ  ‚îÇ
                     ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                               ‚îÇ
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ                ORCHESTRATOR (8001)                      ‚îÇ
                     ‚îÇ         LangGraph Router + Schema Validation            ‚îÇ
                     ‚îÇ                         ‚îÇ                               ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ            ‚îÇ                         ‚îÇ                         ‚îÇ     ‚îÇ     ‚îÇ
        ‚ñº            ‚îÇ                         ‚ñº                         ‚ñº     ‚îÇ     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ GUARDIAN    ‚îÇ      ‚îÇ              ‚îÇ   NLU SVENSKA   ‚îÇ         ‚îÇ SMART CACHE ‚îÇ‚îÇ ‚îÇ  SECURITY   ‚îÇ
‚îÇ (8787)      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     (9002)      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ L1/L2/L3    ‚îÇ‚îÇ ‚îÇ  POLICIES   ‚îÇ
‚îÇ Brownout    ‚îÇ      ‚îÇ              ‚îÇ E5+XNLI+Intent  ‚îÇ         ‚îÇ   (6379)    ‚îÇ‚îÇ ‚îÇ PII Masking ‚îÇ
‚îÇ Protection  ‚îÇ      ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ                        ‚îÇ                                ‚îÇ
        ‚îÇ            ‚îÇ                        ‚îÇ                                ‚îÇ
        ‚ñº            ‚îÇ                        ‚ñº                                ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ LOAD BALANCER      ‚îÇ              ‚îÇ  RL/ML SYSTEM   ‚îÇ                        ‚îÇ
‚îÇ Kill Sequence‚îÇ     ‚îÇ              ‚îÇ                 ‚îÇ                        ‚îÇ
‚îÇ Emergency   ‚îÇ      ‚îÇ              ‚îÇ LinUCB Router   ‚îÇ                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ              ‚îÇ Thompson Sample ‚îÇ                        ‚îÇ
                     ‚îÇ              ‚îÇ œÜ-Optimization  ‚îÇ                        ‚îÇ
                     ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
                     ‚îÇ                        ‚îÇ                                ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îê
        ‚îÇ            ‚îÇ                        ‚îÇ                                ‚îÇ  ‚îÇ
        ‚ñº            ‚îÇ                        ‚ñº                                ‚ñº  ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ MEMORY/RAG  ‚îÇ      ‚îÇ              ‚îÇ   TOOL REGISTRY ‚îÇ         ‚îÇ TELEMETRY   ‚îÇ   ‚îÇ
‚îÇ FAISS+Redis ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   MCP + Health  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ P50/P95     ‚îÇ   ‚îÇ
‚îÇ User Memory ‚îÇ      ‚îÇ              ‚îÇ   Latency Class ‚îÇ         ‚îÇ Energy/RAM  ‚îÇ   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                     ‚îÇ                        ‚îÇ                         ‚îÇ         ‚îÇ
                     ‚îÇ                        ‚ñº                         ‚ñº         ‚îÇ
                     ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
                     ‚îÇ              ‚îÇ     OLLAMA      ‚îÇ         ‚îÇ   N8N       ‚îÇ   ‚îÇ
                     ‚îÇ              ‚îÇ  Local Models   ‚îÇ         ‚îÇ Workflows   ‚îÇ   ‚îÇ
                     ‚îÇ              ‚îÇ phi3.5:3.8b + Llama ‚îÇ         ‚îÇ (5678)      ‚îÇ   
                     ‚îÇ              ‚îÇ   (11434)       ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                     ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### File Structure
```
alice-v2/
‚îú‚îÄ‚îÄ apps/               # ‚úÖ Frontend applications
‚îÇ   ‚îî‚îÄ‚îÄ web/            # ‚úÖ Next.js Enterprise HUD with real-time chat
‚îú‚îÄ‚îÄ services/           # Backend services (Python FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator/   # ‚úÖ LangGraph Router with schema validation & API gateway
‚îÇ   ‚îú‚îÄ‚îÄ guardian/       # ‚úÖ System health & admission control
‚îÇ   ‚îú‚îÄ‚îÄ cache/          # ‚úÖ Robust semantic cache with deterministic fingerprinting
‚îÇ   ‚îú‚îÄ‚îÄ eval/           # ‚úÖ Autonomous E2E testing harness
‚îÇ   ‚îú‚îÄ‚îÄ nlu-en/         # ‚úÖ Swedish NLU with e5-embeddings + heuristics
‚îÇ   ‚îú‚îÄ‚îÄ voice/          # ‚úÖ Swedish TTS/STT pipeline (Whisper + Piper)
‚îÇ   ‚îî‚îÄ‚îÄ loadgen/        # ‚úÖ Brownout testing & SLO validation
‚îú‚îÄ‚îÄ training/           # ‚úÖ Phase 2 Swedish NLU training with anti-mode-collapse
‚îú‚îÄ‚îÄ monitoring/         # ‚úÖ Observability tools (Streamlit scripts)
‚îú‚îÄ‚îÄ data/               # ‚úÖ Telemetry & structured logging
‚îú‚îÄ‚îÄ scripts/            # ‚úÖ Autonomous E2E test automation
‚îî‚îÄ‚îÄ test-results/       # ‚úÖ Nightly validation & trends
```

### Architecture at a glance (Solo Edition)
- **LangGraph Router**: Schema validation with contextual routing decisions
- **Fast-route** for time/weather/memory/smalltalk (utan LLM i loopen)
- **ToolSelector** (local 3B, enum-only, strict JSON)
- **Hybrid Planner**: **OpenAI 4o-mini primary** (function-calling, temp=0, max_tokens=40) **+ Local ToolSelector fallback**
- **Budget guard**: auto-switch to local n√§r dagsbudget n√•s
- **n8n** f√∂r tunga/asynkrona jobb via s√§krade webhooks
- **Guardian** skyddar med brownout/circuit‚Äëbreakers + OpenAI policies (rate limit, cost budget)
- **User opt-in** f√∂r cloud processing (cloud_ok flag)
- **Swedish NLU v2** med anti-mode-collapse training systems

## üöÄ Quick Start

### Minimal Setup (Demo)
```bash
git clone https://github.com/DanielWarg/AliceV2.git
cd alice-v2
make up
open http://localhost:3001
```

### Full Setup (Development)

**Prerequisites:**
- Docker Desktop (installed and running)
- Python 3.11+ (for local development)
- pnpm (for frontend: `npm install -g pnpm`)
- Ollama (for local models: https://ollama.ai)

**First time setup:**

```bash
# 1. Install prerequisites
brew install python@3.11 pnpm  # macOS
# or: sudo apt install python3.11 pnpm  # Ubuntu

# 2. Install Docker Desktop
# Download from: https://www.docker.com/products/docker-desktop/

# 3. Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 4. Start Docker Desktop and Ollama
# Docker Desktop: Start the app
# Ollama: ollama serve (runs automatically on macOS)

# 5. Clone the project
git clone https://github.com/your-repo/alice-v2.git
cd alice-v2

# 6. Set environment variables (optional)
export N8N_ENCRYPTION_KEY=change-me
export OPENAI_API_KEY=sk-your-key-here  # When we implement OpenAI

# 7. Start everything!
make up
```

**After the first time, just run:**
```bash
git pull
make up
```

### üéØ One-Command Setup (Recommended)
```bash
# Clone and enter directory
git clone <repository>
cd alice-v2

# Start everything automatically (venv + deps + models + stack + tests)
make up

# Run all tests to verify everything works
make test-all

# Access HUD
open http://localhost:3001
```

## ü™ü Windows Setup Guide

This comprehensive guide covers setting up Alice v2 on Windows using WSL2 (Windows Subsystem for Linux) for optimal development experience.

### Prerequisites Overview

- **Windows 10 version 2004+** or **Windows 11** (WSL2 requirement)
- **Administrator access** for initial setup
- **At least 8GB RAM** (16GB recommended for local AI models)
- **20GB+ free disk space** for Docker, models, and dependencies

### Step 1: Enable WSL2 and Install Ubuntu

#### 1.1 Enable WSL2 Feature
Open PowerShell as Administrator and run:

```powershell
# Enable WSL and Virtual Machine Platform
dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart

# Restart required
Restart-Computer
```

#### 1.2 Install WSL2 Kernel Update
1. Download the WSL2 Linux kernel update package from Microsoft
2. Run the installer: `wsl_update_x64.msi`

#### 1.3 Set WSL2 as Default and Install Ubuntu
```powershell
# Set WSL2 as default version
wsl --set-default-version 2

# Install Ubuntu 22.04 LTS (recommended)
wsl --install -d Ubuntu-22.04

# Or install from Microsoft Store: "Ubuntu 22.04.3 LTS"
```

#### 1.4 Complete Ubuntu Setup
1. Launch Ubuntu from Start menu
2. Create your UNIX username and password
3. Update the system:
```bash
sudo apt update && sudo apt upgrade -y
```

### Step 2: Docker Desktop Setup for Windows

#### 2.1 Install Docker Desktop
1. Download Docker Desktop for Windows from: https://www.docker.com/products/docker-desktop/
2. Run the installer with default settings
3. **Important**: Enable "Use WSL 2 based engine" during installation
4. Restart Windows after installation

#### 2.2 Configure Docker for WSL2
1. Start Docker Desktop
2. Go to Settings ‚Üí General
3. Ensure "Use the WSL 2 based engine" is checked
4. Go to Settings ‚Üí Resources ‚Üí WSL Integration
5. Enable integration with your Ubuntu distribution
6. Click "Apply & Restart"

#### 2.3 Verify Docker in WSL2
Open Ubuntu terminal and verify:
```bash
# Check Docker is available in WSL2
docker --version
docker-compose --version

# Test Docker works
docker run hello-world
```

### Step 3: Install Required Dependencies in WSL2

#### 3.1 Install Python 3.11+
```bash
# Add deadsnakes PPA for latest Python versions
sudo apt update
sudo apt install -y software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa -y
sudo apt update

# Install Python 3.11 and essential tools
sudo apt install -y python3.11 python3.11-venv python3.11-dev python3-pip
sudo apt install -y build-essential curl wget git

# Set Python 3.11 as default (optional)
sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1
```

#### 3.2 Install Node.js and pnpm
```bash
# Install Node.js 18+ via NodeSource
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt install -y nodejs

# Install pnpm globally
npm install -g pnpm

# Verify installations
node --version  # Should be v18+
pnpm --version
```

#### 3.3 Install Ollama for Local AI Models
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service
ollama serve &

# Install required models (will download ~2GB each)
ollama pull qwen2.5:3b
ollama pull phi3:mini

# Verify models are installed
ollama list
```

### Step 4: Clone and Setup Alice v2

#### 4.1 Choose Your Setup Location
```bash
# Option 1: WSL2 home directory (better performance)
cd ~
git clone https://github.com/DanielWarg/AliceV2.git alice-v2
cd alice-v2

# Option 2: Windows filesystem (if you need Windows IDE access)
# Note: Slower file I/O performance
cd /mnt/c/Users/YourUsername/Documents
git clone https://github.com/DanielWarg/AliceV2.git alice-v2
cd alice-v2
```

**Recommendation**: Use WSL2 home directory (`~`) for better performance, access files via `\\wsl$\Ubuntu-22.04\home\yourusername` in Windows Explorer.

#### 4.2 Set Up Environment Variables
```bash
# Create .env file from template
cp .env.example .env

# Edit environment variables
nano .env
```

Add these Windows/WSL2 specific settings to `.env`:
```env
# N8N Configuration
N8N_ENCRYPTION_KEY=change-me-to-secure-key

# OpenAI API Key (optional, for cloud features)
OPENAI_API_KEY=sk-your-api-key-here

# WSL2 specific Ollama configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_HOST=http://localhost:11434

# Logging
LOG_LEVEL=INFO
```

### Step 5: Start Alice v2

#### 5.1 Automated Setup (Recommended)
```bash
# Make sure you're in the alice-v2 directory
cd ~/alice-v2  # or wherever you cloned it

# One-command setup: creates venv, installs deps, fetches models, starts stack
make up
```

The `make up` command will automatically:
- Create Python virtual environment
- Install all Python dependencies
- Install Node.js dependencies with pnpm
- Download required AI models
- Start all Docker services
- Launch the frontend HUD

#### 5.2 Manual Setup (Alternative)
If you prefer step-by-step setup:
```bash
# Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install Python dependencies
pip install --upgrade pip
pip install pytest httpx fastapi pyyaml prometheus_client psutil structlog

# Install Node.js dependencies
pnpm install:all

# Fetch AI models
./scripts/fetch_models.sh

# Start Docker services
docker compose up -d

# Start frontend (in separate terminal)
cd apps/hud && pnpm dev
```

### Step 6: Access Alice v2

#### 6.1 Verify Services Are Running
```bash
# Check service health
curl http://localhost:18000/health
curl http://localhost:18000/api/status/simple

# Check Guardian status
curl http://localhost:8787/health
```

#### 6.2 Access Web Interfaces
- **Main HUD**: http://localhost:3001 (Primary dashboard)
- **API Gateway**: http://localhost:18000 (API access)
- **n8n Workflows**: http://localhost:5678 (Automation platform)
- **Monitoring Dashboard**: http://localhost:8501 (when enabled)

#### 6.3 Test the AI Assistant
```bash
# Test basic chat functionality
curl -s -X POST http://localhost:18000/api/chat \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY_HERE' \
  -d '{"v":"1","session_id":"test","lang":"sv","message":"Vad √§r klockan?"}' | jq .
```

### Step 7: Windows-Specific Configuration

#### 7.1 Port Forwarding and Networking
WSL2 uses its own network interface. To access Alice v2 from Windows applications:

```bash
# Check WSL2 IP address
hostname -I

# Windows can access via localhost by default for most ports
# If you have issues, check Windows Firewall settings
```

#### 7.2 File System Integration
- **Access WSL2 files from Windows**: `\\wsl$\Ubuntu-22.04\home\yourusername\alice-v2`
- **Access Windows files from WSL2**: `/mnt/c/Users/YourUsername/...`
- **VS Code integration**: Install "WSL" extension for seamless development

#### 7.3 Performance Optimization
```bash
# Increase WSL2 memory limit (optional)
# Create/edit ~/.wslconfig in Windows home directory
notepad.exe ~/.wslconfig
```

Add to `.wslconfig`:
```ini
[wsl2]
memory=8GB
processors=4
swap=2GB
```

Restart WSL2 after changes:
```powershell
wsl --shutdown
wsl
```

### Step 8: Troubleshooting Common Windows/WSL Issues

#### 8.1 Docker Issues
```bash
# Docker daemon not running
sudo service docker start

# Permission denied errors
sudo usermod -aG docker $USER
# Then logout and login to WSL2

# Docker Desktop integration broken
# Restart Docker Desktop, ensure WSL2 integration is enabled
```

#### 8.2 Port Conflicts
```bash
# Kill conflicting processes
./scripts/ports-kill.sh

# Check what's using ports
sudo netstat -tulpn | grep :8000
sudo netstat -tulpn | grep :3001
```

#### 8.3 Ollama Issues
```bash
# Ollama not responding
pkill ollama
ollama serve &

# Models not downloading
# Check disk space: df -h
# Clear Ollama cache: rm -rf ~/.ollama

# Restart Ollama service
sudo systemctl restart ollama  # if installed as service
# Or manually: ollama serve &
```

#### 8.4 Memory Issues
```bash
# Check memory usage
free -h
docker stats

# Clear Docker cache if needed
docker system prune -f

# Stop unused services
docker compose down
```

#### 8.5 WSL2 Networking Issues
```powershell
# Reset WSL2 network (run in Windows PowerShell as Admin)
wsl --shutdown
netsh winsock reset
netsh int ip reset
# Restart computer
```

### Step 9: Development Workflow on Windows

#### 9.1 Recommended IDE Setup
- **VS Code with WSL extension**: Best integration, works seamlessly with WSL2
- **JetBrains IDEs**: Configure to use WSL2 Python interpreter
- **Windows Terminal**: Modern terminal with WSL2 tab support

#### 9.2 Daily Development Commands
```bash
# Start development environment
make up

# Run tests
make test-all

# Stop services
make down

# View logs
docker compose logs -f orchestrator

# Quick restart
make restart
```

#### 9.3 Git Configuration
```bash
# Configure Git in WSL2
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"
git config --global core.autocrlf input
git config --global core.filemode false
```

### Step 10: Production Considerations

#### 10.1 Security
- Change default passwords in `.env` file
- Use strong N8N encryption keys
- Configure proper firewall rules if exposing services
- Regular updates: `sudo apt update && sudo apt upgrade`

#### 10.2 Backup Strategy
```bash
# Backup configuration and data
tar -czf alice-v2-backup-$(date +%Y%m%d).tar.gz \
  .env docker-compose.yml data/ config/

# Backup to Windows location
cp alice-v2-backup-*.tar.gz /mnt/c/Users/YourUsername/Backups/
```

#### 10.3 Performance Monitoring
```bash
# Monitor system resources
htop
docker stats

# Check Alice v2 performance
curl http://localhost:18000/api/status/simple
```

### Need Help?

If you encounter issues:

1. **Check the logs**: `docker compose logs -f orchestrator`
2. **Run diagnostics**: `./scripts/auto_verify.sh`
3. **Check system resources**: `free -h` and `df -h`
4. **Restart services**: `make restart`
5. **Clean restart**: `make down && make up`

For more advanced troubleshooting, see the main troubleshooting section below.

---

## ‚ö° Solo Quickstart (Local Lite)
```bash
# Start Ollama locally first (not in Docker)
ollama serve &
ollama pull qwen2.5:3b-instruct-q4_K_M

# Start core services (Note: Ollama runs on host, not in Docker)
docker compose up -d guardian orchestrator nlu dev-proxy n8n-db n8n

# Quick test
curl -s -X POST http://localhost:18000/api/chat \
  -H 'Content-Type: application/json' -H 'Authorization: Bearer test-key-123' \
  -d '{"v":"1","session_id":"test","lang":"sv","message":"Vad √§r klockan?"}' | jq .

# Open HUD
open http://localhost:3001
```

### n8n Setup
```bash
# UI: http://localhost:5678 (create account with email)
# Import flows: services/n8n/flows/*.json
# Verify: curl -s http://localhost:5678/healthz
```

### üîß Troubleshooting

```bash
# Common issues
./scripts/ports-kill.sh                    # Port conflicts
docker compose down --remove-orphans        # Container issues
ollama pull qwen2.5:3b phi3:mini           # Missing models
docker compose logs -f orchestrator         # View logs
open http://localhost:3001                  # HUD
```

### üîß Manual Setup (Alternative)
```bash
# Clone and enter directory
git clone <repository>
cd alice-v2

# Start core services via proxy
docker compose up -d guardian orchestrator nlu dev-proxy

# Verify via proxy
curl http://localhost:18000/health
curl http://localhost:18000/api/status/simple

# Run autonomous E2E test (validates everything)
./scripts/auto_verify.sh

# HUD
open http://localhost:3001
```

### üß™ Development Workflow
```bash
# Complete development workflow (up + all tests)
make dev

# Quick development workflow (up + e2e only)
make dev-quick

# Run specific test suites
make test-unit      # Unit tests only
make test-e2e       # E2E tests only
make test-integration # Integration tests only
```

### üõ†Ô∏è Available Commands
```bash
make help           # Show all available commands
make up             # Start development stack (auto-setup)
make down           # Stop development stack
make restart        # Restart development stack
make test-all       # Run complete test suite
make clean          # Clean generated files
make fetch-models   # Download required models
```

## üß† Swedish NLU v2 (Anti-Mode-Collapse)

Alice v2 features advanced Swedish NLU training with comprehensive anti-mode-collapse protection:

### Training Features
- **üêï TrainingWatchdog** - Comprehensive monitoring for divergence, regression, overfitting, hallucination, and mode collapse
- **‚öñÔ∏è WeightedRandomSampler** - Balanced batches ensuring all classes are represented
- **üìä Class-Balanced Loss** - Higher penalties for rare class misclassification  
- **üßä Frozen Encoder** - Prevents catastrophic forgetting with gradual unfreezing
- **üéØ OPUS Gates** - Math F1 ‚â•0.60, Macro F1 ‚â•0.25, Hallucination <1%, Safety ‚â•95%
- **üìà Coverage Slope Monitoring** - Detects mode collapse via embedding diversity

### Training Results
```bash
# Phase 2 Swedish NLU Training (Balanced)
‚úÖ Model loaded: xlm-roberta-base  
‚úÖ Dataset: 206 train, 37 val (balanced across 8 intents)
‚úÖ Class weights: unknown.fallback=1.609 (highest), math.calculate=0.757
üßä Frozen encoder: 10/12 layers (5.3% trainable params)  
‚öñÔ∏è WeightedRandomSampler + Class-balanced cross-entropy + Label smoothing
üêï TrainingWatchdog: Comprehensive monitoring active
```

### Training Infrastructure
```
training/
‚îú‚îÄ‚îÄ example_phase2_balanced.py      # Anti-mode-collapse training
‚îú‚îÄ‚îÄ watchdog_callback.py            # Comprehensive training monitoring  
‚îú‚îÄ‚îÄ compute_metrics_golden_sv.py    # Golden-SV evaluation metrics
‚îú‚îÄ‚îÄ datasets/sv_nlu/v3/             # Balanced Swedish dataset (280 samples)
‚îî‚îÄ‚îÄ scripts/expand_swedish_dataset.py  # Dataset expansion utilities
```

## üéØ Solo Edition (Local Lite)

- **Fast-route**: time/weather/memory/smalltalk utan LLM i loopen
- **Hybrid Planner**: OpenAI primary + local ToolSelector fallback
- **Tool enum-only schema**: model v√§ljer verktyg, args byggs deterministiskt i kod
- **n8n** f√∂r tunga jobb (email_draft, calendar_draft, scrape_and_summarize, batch_rag) via s√§krade webhooks
- **R√∂st**: Whisper.cpp (STT) + Piper (sv‚ÄëSE) f√∂r TTS
- **SLO (solo)**: fast-route p95 ‚â§ 250 ms; planner p95 ‚â§ 900 ms; n8n email_draft p95 ‚â§ 10 s
- **Cost budget**: ‚â§$3/day f√∂r OpenAI; user opt-in f√∂r cloud processing

## üé¨ Demo Guide (3 scenarier)
1) **Boka m√∂te i morgon 14:00**
   - F√∂rv√§ntan: confirmation‚Äëkort (JSON‚Äëplan), d√§refter n8n `calendar_draft` svar
2) **Vad sa vi om leveransen?**
   - F√∂rv√§ntan: memory.query + kort RAG‚Äëcitat i svaret
3) **L√§s upp det**
   - F√∂rv√§ntan: TTS via Piper (svenska)

### Daily Automation (14:00)
```bash
# Install cron job to run auto-verify daily at 14:00 and log to logs/auto_verify.log
chmod +x scripts/setup-cron.sh
./scripts/setup-cron.sh
crontab -l | grep auto_verify
```

## ‚úÖ Quick checklist (daily)

### Completed

- [x] **Observability + eval-harness v1**
- [x] **Security v1 (baseline)**  
- [x] **Swedish NLU v2 with Anti-Mode-Collapse Training**
- [x] **TrainingWatchdog with comprehensive monitoring**
- [x] **WeightedRandomSampler + Class-balanced loss**
- [x] **Frozen encoder training policy**
- [x] **Math FN pattern fixes (3 Swedish cases)**
- [x] **Automated setup with `make up`**
- [x] **Comprehensive test suite with `make test-all`**
- [x] **Repository hygiene and cleanup**

### Next steps

#### Step 4 ‚Äì NLU + XNLI
- [ ] Export XNLI to ONNX (int8) ‚Üí `models/xnli/`
- [ ] Connect entailment for low margin in NLU
- [ ] Add 4‚Äì6 challenging test scenarios to eval-harness
- [ ] Intent accuracy ‚â•92%, P95 ‚â§80ms

#### Step 5 ‚Äì Micro-LLM (Phi-3.5-mini via Ollama)
- [ ] Enable micro-driver in `/api/chat`
- [ ] Set `X-Route=micro` for simple intents
- [ ] Measure P95 <250ms (first token)

#### Step 6 ‚Äì Memory (Redis TTL + FAISS user memory)
- [ ] Session memory TTL=7 days
- [ ] FAISS hot/cold index config (HNSW+ondisk)
- [ ] "Forget me" <1s tested in eval

#### Step 7 ‚Äì Planner (OpenAI 4o-mini + MCP tools)
- [ ] Tool schema = enum-only; deterministic arg-builders + error taxonomy
- [ ] OpenAI rate limit + circuit breaker + budget guard
- [ ] cloud_ok per session (opt-in) + audit log
- [ ] n8n webhooks HMAC-SHA256 + replay-guard
- [ ] Eval with 1‚Äì2 tool-calls/flow
- [ ] Tool success ‚â•95%

#### Step 8 ‚Äì Text E2E hard test
- [ ] Fast: P95 ‚â§250ms
- [ ] Planner: P95 ‚â§900ms (first) / ‚â§1.5s (full)

## üîß Development

### Local Development
```bash
# Start services
docker compose up -d guardian orchestrator

# Development environment
cd services/orchestrator
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Test
curl http://localhost:8000/api/status/simple
curl http://localhost:8787/health

# Run validation
./scripts/auto_verify.sh

# Monitor
cd monitoring && streamlit run mini_hud.py
```

### Testing Strategy
- **E2E Testing**: `./scripts/auto_verify.sh` - Complete system validation
- **Unit Testing**: `pytest` with realistic expectations (80-95% success rates)
- **Load Testing**: `services/loadgen/main.py` - Brownout validation
- **Monitoring**: Real-time HUD with comprehensive metrics

## üìä Monitoring & Observability

### Real-time Dashboard
```bash
# Start HUD
cd monitoring && streamlit run mini_hud.py

# Or via proxy
open http://localhost:18000/hud
```

### Key Metrics
- **Performance**: P50/P95 latency per route, RAM peak per turn
- **Reliability**: Guardian state, error rates, SLO compliance
- **Security**: Injection attempts, tool denials, security mode
- **Quality**: Intent accuracy, tool success rates, eval pass rates
- **Training**: Loss convergence, class balance, mode collapse detection

### Data Collection
- **Telemetry**: Structured JSONL logging under `data/telemetry/`
- **Test Results**: E2E validation artifacts under `data/tests/`
- **Trends**: Nightly validation trends under `test-results/`
- **Training Data**: Model training artifacts under `training/`

## üõ°Ô∏è Security Features

- **Guardian System**: Real-time health monitoring with automatic brownout
- **Injection Detection**: Pattern-based injection attempt detection
- **Tool Firewall**: Configurable tool access control
- **Security Policy**: YAML-based security configuration
- **OpenAI guardrails**: Rate limit, circuit breaker, daily/weekly budget (auto fallback to local)
- **n8n webhooks**: HMAC-SHA256 (X-Alice-Timestamp, X-Alice-Signature), ¬±300s window, replay-block via Redis SETNX
- **cloud_ok**: Per-session opt-in required before any cloud call
- **Training Security**: TrainingWatchdog prevents model poisoning and mode collapse

## üìö Documentation

- **`ROADMAP.md`** - Live milestone tracker with test gates
- **`ALICE_SYSTEM_BLUEPRINT.md`** - System architecture and design decisions
- **`TESTING_STRATEGY.md`** - Comprehensive testing approach
- **`SECURITY_AND_PRIVACY.md`** - Security measures, GDPR compliance, and AI Act transparency
- **`training/`** - Swedish NLU v2 training documentation and anti-mode-collapse systems

### üîß For Maintainers
- **`docs/REPO_SETUP.md`** - GitHub repository setup and configuration guide

## üì¶ Release Tags

- `v2.8.0-swedish-nlu-v2`: Swedish NLU v2 with anti-mode-collapse training systems: TrainingWatchdog, WeightedRandomSampler, class-balanced loss, frozen encoder policy, math FN fixes, and comprehensive mode collapse protection. Dataset expanded to 280 balanced samples across 8 intents.

## ü§ù Contributing

See `CONTRIBUTING.md` for development guidelines and contribution process.

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**ü§ñ Built with Claude Code - Alice v2 Swedish NLU v2 with anti-mode-collapse training complete! üöÄ**