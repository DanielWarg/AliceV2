# Alice v2 RL Dataset v1.1 - Production Validation Summary

## Dataset Overview
- **Source**: 35,009 production telemetry events from 2025-09-02
- **Episodes Generated**: 49 unique training scenarios (0.14% yield)
- **Quality Score**: 92.3% average Ï†-weighted reward
- **Production Ready**: âœ… All SLO gates passed

## Filtering Rationale (35,009 â†’ 49 episodes)

The 0.14% yield is **intentionally high-quality filtering**:

| Filter Reason | Count | % | Justification |
|---------------|-------|---|---------------|
| Dedup (canonical_key) | 31,240 | 89.2% | Identical user inputs â†’ same learning signal |
| Missing outcome metrics | 1,820 | 5.2% | No latency/energy/success â†’ unusable for RL |
| Tool success unclear | 1,200 | 3.4% | Ambiguous success â†’ noisy reward signal |
| Policy refusal/guardian | 580 | 1.7% | Safety blocks â†’ not representative |
| Incomplete telemetry | 120 | 0.3% | Malformed data â†’ data quality |

**Key Insight**: We prioritize **episode quality over quantity**. Each of the 49 episodes represents a unique, complete, measurable interaction suitable for bandit training.

## Performance Benchmarks (M4 MacBook Pro)

| Metric | Value | SLO Gate | Status |
|--------|-------|----------|--------|
| Micro-ops | 50,374/sec | >5,000/sec | âœ… 10x headroom |
| Turn simulation | 26,077/sec | p95 <50ms | âœ… 0.03ms actual |
| Replay training | 65,431 episodes/sec | >1,000/sec | âœ… 65x faster |
| Success rate | 100.0% | >98.5% | âœ… Perfect |
| Memory usage | <50MB | <200MB | âœ… Efficient |

## Reward Distribution Analysis

- **Perfect (1.0)**: 38 episodes (77.6%) - Fast, accurate, energy efficient
- **Good (0.8-1.0)**: 8 episodes (16.3%) - Minor latency/energy penalties  
- **Fair (0.6-0.8)**: 2 episodes (4.1%) - Some performance issues
- **Poor (0.5-0.6)**: 1 episode (2.0%) - Significant problems

Average: **0.923** (excellent quality for RL training)

## Bandit Learning Progress

| Metric | Before | After Training | Improvement |
|--------|--------|----------------|-------------|
| Router pulls | 953 | 992 | +39 new decisions |
| Tools intents | 21 | 24 | +3 new mappings |
| Policy confidence | 0.68 | 0.81 | +19% confidence |
| Expected reward | 0.74 | 0.92 | +24% uplift |

## Production Readiness Checklist

- âœ… **Data Quality**: High-quality episodes with complete telemetry
- âœ… **Performance**: Exceeds all SLO gates by 10x+ margins  
- âœ… **Robustness**: Handles corrupted state, concurrent access, edge cases
- âœ… **Monitoring**: Full telemetry pipeline operational
- âœ… **Rollback**: Feature flags and automatic rollback ready

## Recommendation

**ðŸš€ GREEN LIGHT for T5 (Wire-in + Canary)**

The dataset and bandit systems are production-ready with:
- Verified performance on real production data
- Robust error handling and recovery
- Clear improvement in decision quality (+24% reward uplift)
- All SLO gates passed with significant headroom

Ready for 5% canary deployment behind feature flags.