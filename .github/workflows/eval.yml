name: Eval Harness
on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  eval:
    runs-on: ubuntu-latest
    services:
      redis:
        image: redis:7-alpine
        ports: ['6379:6379']
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp pyyaml
          
      - name: Start Alice services
        run: |
          # Create minimal .env for CI
          echo "OPENAI_API_KEY=fake-key-for-ci" > .env
          echo "N8N_DB_PASSWORD=test" >> .env
          echo "N8N_ENCRYPTION_KEY=fake-key-for-ci-testing" >> .env
          
          # Start Alice services in background (NLU without Ollama dependency)
          docker compose up -d guardian alice-cache
          # Start NLU without healthcheck dependency on Ollama
          docker compose up -d --no-deps nlu
          # Start orchestrator last
          docker compose up -d --no-deps orchestrator
          
          # Wait for services to be healthy (increased timeout for CI)
          echo "Waiting for Alice services to be ready..."
          timeout 300 bash -c 'until curl -f http://localhost:18000/health; do sleep 10; done'
          
      - name: Run regression tests
        run: |
          # Create eval_runs directory
          mkdir -p eval_runs
          
          # Run evaluation harness
          python eval/harness.py \
            --base-url http://localhost:18000 \
            --regression-dir eval/regression \
            --output eval_runs/${GITHUB_SHA}.json
            
      - name: Run quality gates
        run: |
          python scripts/qg.py eval_runs/${GITHUB_SHA}.json --verbose
          
      - name: Upload evaluation report
        uses: actions/upload-artifact@v4
        with:
          name: eval-${{ github.sha }}
          path: eval_runs/${GITHUB_SHA}.json
          
      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const reportPath = `eval_runs/${context.sha}.json`;
            
            if (fs.existsSync(reportPath)) {
              const report = JSON.parse(fs.readFileSync(reportPath, 'utf8'));
              const metrics = report.metrics;
              
              const comment = `## 📊 Evaluation Results
              
              **SHA**: ${report.sha}
              **Planner**: ${report.planner}
              **Schema**: ${report.schema}
              
              ### Metrics
              - **EASY schema_ok@first**: ${(metrics['easy.schema_ok_first'] * 100).toFixed(1)}%
              - **MEDIUM schema_ok@first**: ${(metrics['medium.schema_ok_first'] * 100).toFixed(1)}%
              - **HARD schema_ok@first**: ${(metrics['hard.schema_ok_first'] * 100).toFixed(1)}%
              - **Tool precision**: ${(metrics['tool_precision'] * 100).toFixed(1)}%
              - **Latency P95**: ${metrics['latency_p95_ms'].toFixed(0)}ms
              - **Success rate**: ${(metrics['success_rate'] * 100).toFixed(1)}%
              
              ### Quality Gates
              - **EASY+MEDIUM schema_ok ≥ 95%**: ${((metrics['easy.schema_ok_first'] + metrics['medium.schema_ok_first']) / 2 >= 0.95) ? '✅ PASS' : '❌ FAIL'}
              - **Tool precision ≥ 85%**: ${(metrics['tool_precision'] >= 0.85) ? '✅ PASS' : '❌ FAIL'}
              - **Latency P95 ≤ 900ms**: ${(metrics['latency_p95_ms'] <= 900) ? '✅ PASS' : '❌ FAIL'}
              
              **Total scenarios**: ${report.total_scenarios}
              **Successful scenarios**: ${report.successful_scenarios}
              
              📊 [View detailed report](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
              `;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                body: comment
              });
            }
